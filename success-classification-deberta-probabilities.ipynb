{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["y = 'Success_Close'\n","start_from = 1\n","\n","#This is done for Success Close and mainbaord. We can do the same for Success High & Success High for SME."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import warnings\n","import time\n","warnings.filterwarnings(\"ignore\")\n","main = pd.read_excel(\"/kaggle/input/main-board-final-v18/ipo_mainline_final_data_v18.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["main"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = main[main['Close Year'] < 2023]\n","test = main[main['Close Year'] == 2023]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text_features = [\"full_text_content\",'answer_of_question_1',\t'answer_of_question_2',\t'answer_of_question_3','answer_of_question_4','answer_of_question_5','answer_of_question_6','answer_of_question_7','answer_of_question_8','answer_of_question_9','answer_of_question_10','answer_of_question_11','answer_of_question_12','answer_of_question_13','answer_of_question_14','answer_of_question_15','answer_of_question_16','answer_of_question_17','answer_of_question_18','answer_of_question_19','answer_of_question_20','answer_of_question_21','answer_of_question_22','answer_of_question_23','answer_of_question_24','answer_of_question_25']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n","def preprocess_function(examples):\n","    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","import torch\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","import os\n","import shutil\n","\n","\n","output_folder = \"probability_outputs\"\n","os.makedirs(output_folder, exist_ok=True)\n","\n","full_df = main.copy()\n","\n","start = time.time()\n","\n","# Preprocessing to handle NaN entries in the text columns\n","#for idx, feature in enumerate(tqdm(text_features, desc=\"Processing Features\"), 1):\n","for idx, feature in enumerate(tqdm(text_features[(start_from-1):], desc=\"Processing Features\"), start_from):\n","    if (time.time() - start) < (11.5*60*60):\n","        # Replace NaN entries with an empty string (you can modify this if you want a different placeholder)\n","        full_df[feature].fillna('', inplace=True)\n","\n","        full_data = pd.DataFrame({'text': full_df[feature], 'labels': full_df[y]})\n","        full_dataset = Dataset.from_pandas(full_data)\n","        full_dataset = full_dataset.map(preprocess_function, batched=True)\n","\n","        model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=2)\n","\n","        training_args = TrainingArguments(\n","            output_dir=f\"./results-{feature}\",          # Output directory (can be ignored, we don't save models)\n","            evaluation_strategy=\"no\",                   # No evaluation during training\n","            learning_rate=2e-5,                         # Learning rate\n","            per_device_train_batch_size=8,              # Batch size for training\n","            per_device_eval_batch_size=8,               # Batch size for evaluation\n","            num_train_epochs=3,                         # Number of epochs\n","            weight_decay=0.01,                          # Strength of weight decay\n","            logging_dir=None,                           # No logging\n","            save_total_limit=0,                         # No saving of checkpoints\n","            save_steps=0,                               # No saving steps\n","            load_best_model_at_end=False                # No need to load best model\n","        )\n","\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=full_dataset,\n","            tokenizer=tokenizer\n","        )\n","\n","        with tqdm(total=training_args.num_train_epochs, desc=f\"Training for feature '{feature}'\", leave=False) as pbar:\n","            for epoch in range(training_args.num_train_epochs):\n","                trainer.train()\n","                pbar.update(1)  # Update progress bar for each epoch\n","\n","        predictions = trainer.predict(full_dataset)\n","        preds_proba = torch.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n","\n","        feature_probabilities_df = pd.DataFrame({\n","            f'{feature}_class_0_prob': preds_proba[:, 0],  # Probability for class 0\n","            f'{feature}_class_1_prob': preds_proba[:, 1]   # Probability for class 1\n","        })\n","\n","        output_file = os.path.join(output_folder, f'classification_probabilities_{idx}.csv')\n","        feature_probabilities_df.to_csv(output_file, index=False)\n","        print(f\"Probabilities for feature '{feature}' saved to {output_file}\")\n","\n","        preds_labels = preds_proba.argmax(axis=1)\n","        true_labels = full_df['Success_Close'].values\n","        accuracy = accuracy_score(true_labels, preds_labels)\n","        print(f\"Accuracy for feature '{feature}': {accuracy:.4f}\")\n","        #os.rmdir(f\"./results-{feature}\")\n","        shutil.rmtree(f\"./results-{feature}\")\n","\n","print(\"All feature probabilities have been processed and saved.\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5694943,"sourceId":9386174,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
